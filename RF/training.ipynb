{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:47.775231Z",
     "iopub.status.busy": "2025-04-27T06:35:47.774611Z",
     "iopub.status.idle": "2025-04-27T06:35:47.780834Z",
     "shell.execute_reply": "2025-04-27T06:35:47.780078Z",
     "shell.execute_reply.started": "2025-04-27T06:35:47.775205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:47.782500Z",
     "iopub.status.busy": "2025-04-27T06:35:47.781989Z",
     "iopub.status.idle": "2025-04-27T06:35:47.837307Z",
     "shell.execute_reply": "2025-04-27T06:35:47.836671Z",
     "shell.execute_reply.started": "2025-04-27T06:35:47.782481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/cloud-masking-mislabled-flags/23_4_mislabeled_flags.csv\")\n",
    "mislabeled_dict = dict(zip(df[\"filename\"], df[\"mislabeled\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:47.839008Z",
     "iopub.status.busy": "2025-04-27T06:35:47.838581Z",
     "iopub.status.idle": "2025-04-27T06:35:47.997303Z",
     "shell.execute_reply": "2025-04-27T06:35:47.996669Z",
     "shell.execute_reply.started": "2025-04-27T06:35:47.838989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root = \"/kaggle/input/cloud-masking-dataset/content/train\"\n",
    "image_dir = os.path.join(root, \"data\")\n",
    "mask_dir = os.path.join(root, \"masks\")\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) \n",
    "                      if f.endswith('.tif') and mislabeled_dict[f]==\"no\"])\n",
    "mask_files = sorted([os.path.join(mask_dir, f)] for f in os.listdir(mask_dir) \n",
    "                    if f.endswith('.tif') and mislabeled_dict[f]==\"no\")\n",
    "train_imgs, val_imgs, train_masks, val_masks = train_test_split(\n",
    "    image_files, mask_files, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:47.998146Z",
     "iopub.status.busy": "2025-04-27T06:35:47.997962Z",
     "iopub.status.idle": "2025-04-27T06:35:48.004823Z",
     "shell.execute_reply": "2025-04-27T06:35:48.003993Z",
     "shell.execute_reply.started": "2025-04-27T06:35:47.998132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, image_files, mask_files, transforms=None):\n",
    "        self.image_files = image_files\n",
    "        self.mask_files = mask_files\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        mask_path = self.mask_files[idx]\n",
    "\n",
    "        image = tifffile.imread(img_path) \n",
    "        mask = tifffile.imread(mask_path) \n",
    "\n",
    "        if image.shape[0] == 4 and image.shape[-1] != 4:\n",
    "            image = np.transpose(image, (1,2,0)) \n",
    "\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[:, :, 0]  \n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "def get_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(128, 128, interpolation=cv2.INTER_NEAREST, mask_interpolation=cv2.INTER_NEAREST), \n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:48.006780Z",
     "iopub.status.busy": "2025-04-27T06:35:48.006523Z",
     "iopub.status.idle": "2025-04-27T06:35:48.022133Z",
     "shell.execute_reply": "2025-04-27T06:35:48.021381Z",
     "shell.execute_reply.started": "2025-04-27T06:35:48.006764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CloudDataset(\n",
    "    image_files=train_imgs,\n",
    "    mask_files=train_masks,\n",
    "    transforms=get_transforms()\n",
    ")\n",
    "val_dataset = CloudDataset(\n",
    "    image_files=val_imgs,\n",
    "    mask_files=val_masks,\n",
    "    transforms=get_transforms()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:35:48.023239Z",
     "iopub.status.busy": "2025-04-27T06:35:48.022968Z",
     "iopub.status.idle": "2025-04-27T06:35:48.029811Z",
     "shell.execute_reply": "2025-04-27T06:35:48.029293Z",
     "shell.execute_reply.started": "2025-04-27T06:35:48.023214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_ndvi(nir, red):\n",
    "    nir = nir.astype(np.float32)\n",
    "    red = red.astype(np.float32)\n",
    "    ndvi = (nir - red) / (nir + red + 1e-6)\n",
    "    return ndvi\n",
    "\n",
    "def local_variance(image, size=3):\n",
    "    def var_func(x):\n",
    "        return np.var(x)\n",
    "    return generic_filter(image, var_func, size=(size, size))\n",
    "\n",
    "def extract_features(image):\n",
    "    C, H, W = image.shape\n",
    "    features = []\n",
    "\n",
    "    for c in range(C):\n",
    "        features.append(image[c])\n",
    "\n",
    "    nir = image[3] \n",
    "    red = image[0] \n",
    "    ndvi = calculate_ndvi(nir, red)\n",
    "    features.append(ndvi)\n",
    "\n",
    "    for c in range(C):\n",
    "        var_map = local_variance(image[c], size=3)\n",
    "        features.append(var_map)\n",
    "\n",
    "    feature_map = np.stack(features, axis=-1) \n",
    "\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-27T06:38:36.703Z",
     "iopub.execute_input": "2025-04-27T06:35:48.030701Z",
     "iopub.status.busy": "2025-04-27T06:35:48.030511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_rf(dataloader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for images, masks in dataloader:\n",
    "        images = images.numpy()\n",
    "        masks = masks.numpy()  \n",
    "        for i in range(images.shape[0]):\n",
    "            feature_map = extract_features(images[i])\n",
    "            X.append(feature_map.reshape(-1, feature_map.shape[-1]))\n",
    "            y.append(masks[i].reshape(-1))\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    return X, y\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, h, w, num_samples=3):\n",
    "    idxs = np.random.choice(len(y_true)//(h*w), num_samples, replace=False)\n",
    "    for idx in idxs:\n",
    "        start = idx * (h*w)\n",
    "        end = (idx+1) * (h*w)\n",
    "        true_mask = y_true[start:end].reshape(h, w)\n",
    "        pred_mask = y_pred[start:end].reshape(h, w)\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(true_mask, cmap='gray')\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(pred_mask, cmap='gray')\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "X_train, y_train = prepare_data_rf(train_loader)\n",
    "print(\"Preparing validation data...\")\n",
    "X_val, y_val = prepare_data_rf(val_loader)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=8, n_jobs=-1, verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "miou = jaccard_score(y_val, y_pred)\n",
    "print(f\"Validation mIoU: {miou:.4f}\")\n",
    "\n",
    "h, w = 128, 128\n",
    "visualize_predictions(y_val, y_pred, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-27T06:38:36.703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf, \"rf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7068540,
     "sourceId": 11302639,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7236605,
     "sourceId": 11539265,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
